import streamlit as st
import requests
import random
import time
import urllib.parse
import mplfinance as mpf
import FinanceDataReader as fdr
import tiktoken
from bs4 import BeautifulSoup
from datetime import datetime, timedelta
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.vectorstores import FAISS
from langchain.chat_models import ChatOpenAI
from langchain.chains import ConversationalRetrievalChain
from langchain.memory import ConversationBufferMemory

def main():
    st.set_page_config(page_title="Stock Analysis Chatbot", page_icon=":chart_with_upwards_trend:")
    st.title("_ê¸°ì—… ì •ë³´ ë¶„ì„ ë° ì£¼ê°€ ì˜ˆì¸¡ :red[QA Chat]_ :chart_with_upwards_trend:")

    if "conversation" not in st.session_state:
        st.session_state.conversation = None
    if "chat_history" not in st.session_state:
        st.session_state.chat_history = None
    if "processComplete" not in st.session_state:
        st.session_state.processComplete = None

    with st.sidebar:
        openai_api_key = st.text_input("OpenAI API Key", key="chatbot_api_key", type="password")
        company_name = st.text_input("ë¶„ì„í•  ê¸°ì—…ëª… (ì½”ìŠ¤í”¼ ìƒì¥)")
        process = st.button("ë¶„ì„ ì‹œì‘")

    if process:
        if not openai_api_key or not company_name:
            st.info("OpenAI API í‚¤ì™€ ê¸°ì—…ëª…ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            st.stop()

        news_data = crawl_news(company_name)
        if not news_data:
            st.warning("í•´ë‹¹ ê¸°ì—…ì˜ ìµœê·¼ ë‰´ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            st.stop()

        text_chunks = get_text_chunks(news_data)
        vectorstore = get_vectorstore(text_chunks)

        st.session_state.conversation = create_chat_chain(vectorstore, openai_api_key)
        st.session_state.processComplete = True

        st.subheader(f"ğŸ“ˆ {company_name} ìµœê·¼ ì£¼ê°€ ì¶”ì´")
        visualize_stock(company_name, "ì¼")

        with st.chat_message("assistant"):
            st.markdown("ğŸ“¢ ìµœê·¼ ê¸°ì—… ë‰´ìŠ¤ ëª©ë¡:")
            for news in news_data:
                st.markdown(f"- **{news['title']}** ([ë§í¬]({news['link']}))")

    if query := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”."):
        with st.chat_message("user"):
            st.markdown(query)

        with st.chat_message("assistant"):
            with st.spinner("ë¶„ì„ ì¤‘..."):
                result = st.session_state.conversation({"question": query})
                response = result['answer']

                st.markdown(response)
                with st.expander("ì°¸ê³  ë‰´ìŠ¤ í™•ì¸"):
                    for doc in result['source_documents']:
                        st.markdown(f"- [{doc.metadata['source']}]({doc.metadata['source']})")

def crawl_news(company):
    today = datetime.today()
    start_date = (today - timedelta(days=5)).strftime('%Y%m%d')
    end_date = today.strftime('%Y%m%d')
    encoded_query = urllib.parse.quote(company)
    url = f"https://search.naver.com/search.naver?where=news&query={encoded_query}&nso=so:r,p:from{start_date}to{end_date}"
    headers = {"User-Agent": "Mozilla/5.0"}
    response = requests.get(url, headers=headers)
    response.raise_for_status()
    soup = BeautifulSoup(response.text, 'html.parser')
    articles = soup.select("ul.list_news > li")

    data = []
    for article in articles[:10]:
        title = article.select_one("a.news_tit").text
        link = article.select_one("a.news_tit")['href']
        content = article.select_one("div.news_dsc").text if article.select_one("div.news_dsc") else ""
        data.append({"title": title, "link": link, "content": content})

    return data

def tiktoken_len(text):
    tokenizer = tiktoken.get_encoding("cl100k_base")
    tokens = tokenizer.encode(text)
    return len(tokens)

def get_text_chunks(news_data):
    # ë‰´ìŠ¤ ìš”ì•½ ì—†ì´ ì œëª©ê³¼ ë‚´ìš©ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©
    texts = [f"{item['title']}\n{item['content']}" for item in news_data]
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=900,
        chunk_overlap=100,
        length_function=tiktoken_len
    )
    return text_splitter.create_documents(texts)

def get_vectorstore(text_chunks):
    embeddings = HuggingFaceEmbeddings(
        model_name="jhgan/ko-sroberta-multitask",
        model_kwargs={'device': 'cpu'},
        encode_kwargs={'normalize_embeddings': True}
    )
    return FAISS.from_documents(text_chunks, embeddings)

def create_chat_chain(vectorstore, openai_api_key):
    llm = ChatOpenAI(openai_api_key=openai_api_key, model_name='gpt-4', temperature=0)
    return ConversationalRetrievalChain.from_llm(
        llm=llm, chain_type="stuff", retriever=vectorstore.as_retriever(),
        memory=ConversationBufferMemory(memory_key='chat_history', return_messages=True, output_key='answer'),
        get_chat_history=lambda h: h, return_source_documents=True)

def get_ticker(company):
    """
    fdr.StockListing('KRX')ë¡œë¶€í„° ì…ë ¥í•œ íšŒì‚¬ëª…ì— í•´ë‹¹í•˜ëŠ” í‹°ì»¤ ì½”ë“œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    í™˜ê²½ì— ë”°ë¼ ì»¬ëŸ¼ëª…ì´ ë‹¤ë¥¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ëª¨ë‘ í™•ì¸í•©ë‹ˆë‹¤.
    """
    try:
        listing = fdr.StockListing('KRX')
        # ì»¬ëŸ¼ëª…ì„ í™•ì¸í•©ë‹ˆë‹¤.
        if "Symbol" in listing.columns and "Name" in listing.columns:
            name_col = "Name"
            ticker_col = "Symbol"
        elif "ì¢…ëª©ì½”ë“œ" in listing.columns and "ê¸°ì—…ëª…" in listing.columns:
            name_col = "ê¸°ì—…ëª…"
            ticker_col = "ì¢…ëª©ì½”ë“œ"
        else:
            st.error("KRX ìƒì¥ ê¸°ì—… ì •ë³´ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None

        ticker_row = listing[listing[name_col] == company]
        if ticker_row.empty:
            return None
        else:
            ticker = ticker_row.iloc[0][ticker_col]
            # í‹°ì»¤ê°€ ìˆ«ìì¼ ê²½ìš° 6ìë¦¬ ë¬¸ìì—´ë¡œ ë³€í™˜ (ì˜ˆ: '5930' -> '005930')
            return str(ticker).zfill(6)
    except Exception as e:
        st.error(f"í‹°ì»¤ ë³€í™˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

def visualize_stock(company, period):
    ticker = get_ticker(company)
    if not ticker:
        st.error("í•´ë‹¹ ê¸°ì—…ì˜ í‹°ì»¤ ì½”ë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì˜¬ë°”ë¥¸ ê¸°ì—…ëª…ì„ ì…ë ¥í–ˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return

    try:
        df = fdr.DataReader(ticker, '2024-01-01')
    except Exception as e:
        st.error(f"ì£¼ê°€ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return

    if period == "ì¼":
        df = df.tail(30)
    elif period == "ì£¼":
        df = df.resample('W').last()
    elif period == "ì›”":
        df = df.resample('M').last()
    elif period == "ë…„":
        df = df.resample('Y').last()
    mpf.plot(df, type='candle', style='charles', title=f"{company}({ticker}) ì£¼ê°€ ({period})", volume=True)

if __name__ == '__main__':
    main()
