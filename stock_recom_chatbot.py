import streamlit as st
import requests
import random
import time
import urllib.parse
import mplfinance as mpf
import FinanceDataReader as fdr
#import chromadb
import tiktoken
from bs4 import BeautifulSoup
from datetime import datetime, timedelta
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.vectorstores import FAISS
from langchain.chat_models import ChatOpenAI
from langchain.chains import ConversationalRetrievalChain
from langchain.memory import ConversationBufferMemory
from transformers import pipeline


def main():
    st.set_page_config(page_title="Stock Analysis Chatbot", page_icon=":chart_with_upwards_trend:")
    st.title("_Í∏∞ÏóÖ Ï†ïÎ≥¥ Î∂ÑÏÑù Î∞è Ï£ºÍ∞Ä ÏòàÏ∏° :red[QA Chat]_ :chart_with_upwards_trend:")

    if "conversation" not in st.session_state:
        st.session_state.conversation = None
    if "chat_history" not in st.session_state:
        st.session_state.chat_history = None
    if "processComplete" not in st.session_state:
        st.session_state.processComplete = None

    with st.sidebar:
        openai_api_key = st.text_input("OpenAI API Key", key="chatbot_api_key", type="password")
        company_name = st.text_input("Î∂ÑÏÑùÌï† Í∏∞ÏóÖÎ™Ö (ÏΩîÏä§Ìîº ÏÉÅÏû•)")
        process = st.button("Î∂ÑÏÑù ÏãúÏûë")

    if process:
        if not openai_api_key or not company_name:
            st.info("OpenAI API ÌÇ§ÏôÄ Í∏∞ÏóÖÎ™ÖÏùÑ ÏûÖÎ†•Ìï¥Ï£ºÏÑ∏Ïöî.")
            st.stop()

        news_data = crawl_news(company_name)
        if not news_data:
            st.warning("Ìï¥Îãπ Í∏∞ÏóÖÏùò ÏµúÍ∑º Îâ¥Ïä§Î•º Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§.")
            st.stop()

        text_chunks = get_text_chunks(news_data)
        vectorstore = get_vectorstore(text_chunks)

        st.session_state.conversation = create_chat_chain(vectorstore, openai_api_key)
        st.session_state.processComplete = True

        st.subheader(f"üìà {company_name} ÏµúÍ∑º Ï£ºÍ∞Ä Ï∂îÏù¥")
        visualize_stock(company_name, "Ïùº")

    if query := st.chat_input("ÏßàÎ¨∏ÏùÑ ÏûÖÎ†•Ìï¥Ï£ºÏÑ∏Ïöî."):
        with st.chat_message("user"):
            st.markdown(query)

        with st.chat_message("assistant"):
            with st.spinner("Î∂ÑÏÑù Ï§ë..."):
                result = st.session_state.conversation({"question": query})
                response = result['answer']

                st.markdown(response)
                with st.expander("Ï∞∏Í≥† Îâ¥Ïä§ ÌôïÏù∏"):
                    for doc in result['source_documents']:
                        st.markdown(f"- [{doc.metadata['source']}]({doc.metadata['source']})")


def crawl_news(company):
    today = datetime.today()
    start_date = (today - timedelta(days=5)).strftime('%Y%m%d')
    end_date = today.strftime('%Y%m%d')
    encoded_query = urllib.parse.quote(company)
    url = f"https://search.naver.com/search.naver?where=news&query={encoded_query}&nso=so:r,p:from{start_date}to{end_date}"
    headers = {"User-Agent": "Mozilla/5.0"}
    response = requests.get(url, headers=headers)
    response.raise_for_status()
    soup = BeautifulSoup(response.text, 'html.parser')
    articles = soup.select("ul.list_news > li")

    data = []
    summarizer = pipeline("summarization")
    for article in articles[:10]:
        title = article.select_one("a.news_tit").text
        link = article.select_one("a.news_tit")['href']
        content = article.select_one("div.news_dsc").text if article.select_one("div.news_dsc") else ""
        summary = summarizer(content, max_length=100, min_length=30, do_sample=False)[0]['summary_text']
        data.append({"title": title, "link": link, "summary": summary})

    return data


def tiktoken_len(text):
    tokenizer = tiktoken.get_encoding("cl100k_base")
    tokens = tokenizer.encode(text)
    return len(tokens)


def get_text_chunks(news_data):
    texts = [f"{item['title']}\n{item['summary']}" for item in news_data]
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=900,
        chunk_overlap=100,
        length_function=tiktoken_len
    )
    return text_splitter.create_documents(texts)


def get_vectorstore(text_chunks):
    embeddings = HuggingFaceEmbeddings(
        model_name="jhgan/ko-sroberta-multitask",
        model_kwargs={'device': 'cpu'},
        encode_kwargs={'normalize_embeddings': True}
    )
    return FAISS.from_documents(text_chunks, embeddings)


def create_chat_chain(vectorstore, openai_api_key):
    llm = ChatOpenAI(openai_api_key=openai_api_key, model_name='gpt-4', temperature=0)
    return ConversationalRetrievalChain.from_llm(
        llm=llm, chain_type="stuff", retriever=vectorstore.as_retriever(),
        memory=ConversationBufferMemory(memory_key='chat_history', return_messages=True, output_key='answer'),
        get_chat_history=lambda h: h, return_source_documents=True)


def visualize_stock(symbol, period):
    df = fdr.DataReader(symbol, '2024-01-01')
    if period == "Ïùº":
        df = df.tail(30)
    elif period == "Ï£º":
        df = df.resample('W').last()
    elif period == "Ïõî":
        df = df.resample('M').last()
    elif period == "ÎÖÑ":
        df = df.resample('Y').last()
    mpf.plot(df, type='candle', style='charles', title=f"{symbol} Ï£ºÍ∞Ä ({period})", volume=True)


if __name__ == '__main__':
    main()
